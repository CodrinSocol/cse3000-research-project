{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1ea7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import json\n",
    "import lcdb\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import sklearn.model_selection\n",
    "from directencoder import DirectEncoder\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7519f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Init\n",
    "db = pd.read_csv('data/database-accuracy.csv')\n",
    "monotonicity_violations = pd.read_csv('data/monotonicityviolations_logloss.csv')\n",
    "encoder = DirectEncoder(2)\n",
    "\n",
    "outer_seed = 0\n",
    "inner_seed_index = 0\n",
    "num_seeds = 5\n",
    "outer_seeds = list(range(0,10))\n",
    "inner_seeds = list(range(num_seeds * inner_seed_index, num_seeds * (inner_seed_index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec20fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_slopes_by_train(anchors, openml_id, learner_name, outer_seeds, inner_seeds, plotting=False):\n",
    "    X, y = lcdb.get_dataset(openml_id)\n",
    "    slopes = []\n",
    "    n = len(anchors)\n",
    "    \n",
    "    # Code from LCDB paper\n",
    "    learner_params = {}\n",
    "    if learner_name == \"SVC_linear\":\n",
    "        learner_name = \"sklearn.svm.LinearSVC\"\n",
    "    elif learner_name == \"SVC_poly\":\n",
    "        learner_name = \"sklearn.svm.SVC\"\n",
    "        learner_params = {\"kernel\": \"poly\"}\n",
    "    elif learner_name == \"SVC_rbf\":\n",
    "        learner_name = \"sklearn.svm.SVC\"\n",
    "        learner_params = {\"kernel\": \"rbf\"}\n",
    "    elif learner_name == \"SVC_sigmoid\":\n",
    "        learner_name = \"sklearn.svm.SVC\"\n",
    "        learner_params = {\"kernel\": \"sigmoid\"}\n",
    "    \n",
    "    \n",
    "    for idx,anchor in enumerate(anchors):\n",
    "        points = None\n",
    "        if idx == 0:\n",
    "            points = range(anchor, anchor+21)\n",
    "        if idx == n - 1:\n",
    "            points = range(anchor-20, anchor+1)\n",
    "        else:\n",
    "            points = range(anchor-10, anchor+11)\n",
    "        points = np.array(points).reshape(-1,1)\n",
    "        err_lin_reg = []\n",
    "        err_lin_points = []\n",
    "        for anch in points:\n",
    "            measurements = []\n",
    "            for outer_seed in outer_seeds:\n",
    "                for inner_seed in inner_seeds:\n",
    "                    try:\n",
    "                        info = lcdb.get_entry(learner_name, {}, X,y, anch[0], outer_seed, inner_seed)\n",
    "                        y_pred = encoder.decode_label_vector(info['y_hat_train'])\n",
    "                        y_true = encoder.decode_label_vector(info['y_train'])\n",
    "                        \n",
    "                        err = 1 - metrics.accuracy_score(y_true, y_pred)\n",
    "                        err_lin_reg.append(err)\n",
    "                        err_lin_points.append(anch)\n",
    "                    except Exception as e:\n",
    "                        print(\"Invalid \" + str(openml_id) + \" \" + learner_name + \" \" + e)\n",
    "#             err_lin_reg.append(np.mean(measurements))\n",
    "            \n",
    "        lin_reg = LinearRegression()\n",
    "        lin_reg.fit(err_lin_points, err_lin_reg)\n",
    "        \n",
    "#         a = lin_reg.coef_[0]\n",
    "#         b=0\n",
    "#         fst = a + points[0] + b\n",
    "#         lst = a + points[19] + b\n",
    "\n",
    "        if plotting == True:\n",
    "            plt.plot(points, lin_reg.predict(points), color='k')\n",
    "\n",
    "        slopes.append(lin_reg.coef_[0])\n",
    "    return slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5defce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(anchors, errors, color='green'):\n",
    "\n",
    "    print(anchors)\n",
    "    print(errors)\n",
    "    n = min(len(anchors), len(errors))\n",
    "    plt.scatter(anchors[0:n], errors[0:n], color=color)\n",
    "    plt.plot(anchors[0:n], errors[0:n], color=color, label='monotone')\n",
    "\n",
    "def plot_monotonicity(anchors, err, openml_id, learner_name, slopes=None):\n",
    "    fig,ax = plt.subplots()\n",
    "    non_monotone_flag = False    \n",
    "    max_violation_anchor = monotonicity_violations[(monotonicity_violations['openmlid'] == openml_id) & (monotonicity_violations['learner'] == learner_name)]['max_violation_anchor'].iloc[0]\n",
    "    \n",
    "    if slopes == None:\n",
    "        return\n",
    "    \n",
    "    errors = [np.mean(x) for x in err]\n",
    "    plot_curve(anchors, errors)\n",
    "    \n",
    "    for idx, anchor in enumerate(anchors):\n",
    "        if idx >= len(slopes) or idx >= len(errors):\n",
    "            continue\n",
    "            \n",
    "        if slopes[idx] >= 0:\n",
    "            plt.scatter(anchor, errors[idx], color='red')\n",
    "#             non_monotone_flag = True\n",
    "            if (idx < len(anchors)- 1 and slopes[idx+1] >= 0):\n",
    "                plt.plot([anchor, anchors[idx+1]], [errors[idx], errors[idx+1]], color='red')\n",
    "                non_monotone_flag = True\n",
    "            \n",
    "        if idx > 0 and errors[idx] > errors[idx - 1]:\n",
    "            plt.plot([anchor, anchors[idx-1]], [errors[idx], errors[idx-1]], color='red')\n",
    "        if idx < len(anchors) - 1 and errors[idx] < errors[idx + 1]:\n",
    "            plt.plot([anchor, anchors[idx+1]], [errors[idx], errors[idx+1]], color='red')\n",
    "#                 non_monotone_flag = True\n",
    "    \n",
    "    if(max_violation_anchor > 0):\n",
    "        plt.scatter(max_violation_anchor, errors[anchors.index(max_violation_anchor)], color='yellow', label='max violation')\n",
    "    \n",
    "    plt.title(f'LC of learner {learner_name} on dataset_id {openml_id}')\n",
    "    red_patch = mpatches.Patch(color='red', label='non-monotone', linewidth=2)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles.append(red_patch)\n",
    "    plt.legend(handles=handles)\n",
    "    \n",
    "    \n",
    "#     plt.legend()\n",
    "    if non_monotone_flag == True:\n",
    "        plt.savefig('plots/non-monotone/' + str(openml_id) + ' ' + learner_name + '.png')\n",
    "    else:\n",
    "        plt.savefig('plots/monotone/' + str(openml_id) + ' ' + learner_name + '.png')\n",
    "    print(slopes)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9486d19",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m curve \u001b[38;5;241m=\u001b[39m lcdb\u001b[38;5;241m.\u001b[39mget_curve(openml_id, learner_name) \u001b[38;5;66;03m# Default metric == accuracy\u001b[39;00m\n\u001b[0;32m      5\u001b[0m errors \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39my \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m curve[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;66;03m# Transform accuracy in error rate\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m slopes \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_slopes_by_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurve\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenml_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearner_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mouter_seeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_seeds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m, in \u001b[0;36mcalc_slopes_by_train\u001b[1;34m(anchors, openml_id, learner_name, outer_seeds, inner_seeds, plotting)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inner_seed \u001b[38;5;129;01min\u001b[39;00m inner_seeds:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 37\u001b[0m         info \u001b[38;5;241m=\u001b[39m \u001b[43mlcdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_entry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mouter_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mdecode_label_vector(info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_hat_train\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     39\u001b[0m         y_true \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mdecode_label_vector(info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\lcdb\\lcdb.py:225\u001b[0m, in \u001b[0;36mget_entry\u001b[1;34m(learner_name, learner_params, X, y, anchor, outer_seed, inner_seed, encoder, verbose, max_train_predictions)\u001b[0m\n\u001b[0;32m    222\u001b[0m learner_inst \u001b[38;5;241m=\u001b[39m learner_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlearner_params)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# run learner\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m y_train, y_valid, y_test, y_hat_train, y_prob_train, y_hat_valid, y_prob_valid, y_hat_test, y_prob_test, known_labels, train_time, predict_time_train, predict_proba_time_train, predict_time_valid, predict_proba_time_valid, predict_time_test, predict_proba_time_test \u001b[38;5;241m=\u001b[39m \u001b[43mget_truth_and_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner_inst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mouter_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# if the number of training instances was larget than max_train_predictions, only store a random subset (based on the inner seed)\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_train) \u001b[38;5;241m>\u001b[39m max_train_predictions:\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\lcdb\\lcdb.py:174\u001b[0m, in \u001b[0;36mget_truth_and_predictions\u001b[1;34m(learner_inst, X, y, anchor, outer_seed, inner_seed, timeout, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearner_inst\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on data of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m using outer seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mouter_seed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and inner seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_seed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deadline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     \u001b[43mlearner_inst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     func_timeout(deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime(), learner_inst\u001b[38;5;241m.\u001b[39mfit, (X_train, y_train))\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1289\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1291\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:450\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    446\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[0;32m    447\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    448\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    449\u001b[0m ]\n\u001b[1;32m--> 450\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    459\u001b[0m     solver,\n\u001b[0;32m    460\u001b[0m     opt_res,\n\u001b[0;32m    461\u001b[0m     max_iter,\n\u001b[0;32m    462\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    463\u001b[0m )\n\u001b[0;32m    464\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\scipy\\optimize\\_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    694\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 696\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    697\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    699\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    700\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    353\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\scipy\\optimize\\_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\scipy\\optimize\\_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:278\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    276\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[1;32m--> 278\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    285\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2_penalty(weights, l2_reg_strength)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lcfit\\lib\\site-packages\\sklearn\\_loss\\loss.py:257\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[1;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m ReadonlyArrayWrapper(sample_weight)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "openml_id = 60\n",
    "learner_name = 'sklearn.linear_model.LogisticRegression'\n",
    "\n",
    "curve = lcdb.get_curve(openml_id, learner_name) # Default metric == accuracy\n",
    "errors = [[1-y for y in x] for x in curve[1]] # Transform accuracy in error rate\n",
    "\n",
    "slopes = calc_slopes_by_train(curve[0], openml_id, learner_name, outer_seeds, inner_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monotonicity(curve[0], errors, openml_id, learner_name, slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0893780a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       openmlid                                           learner  \\\n",
      "71           57                                        SVC_linear   \n",
      "263          57                                          SVC_poly   \n",
      "455           3                                           SVC_rbf   \n",
      "455          57                                           SVC_rbf   \n",
      "647          57                                       SVC_sigmoid   \n",
      "...         ...                                               ...   \n",
      "55623      4541  sklearn.linear_model.PassiveAggressiveClassifier   \n",
      "55815     42810                 sklearn.naive_bayes.MultinomialNB   \n",
      "56391      1002             sklearn.ensemble.ExtraTreesClassifier   \n",
      "56391     42810               sklearn.tree.DecisionTreeClassifier   \n",
      "56583     42810                  sklearn.tree.ExtraTreeClassifier   \n",
      "\n",
      "       max_anchor_seen                                         prediction  \\\n",
      "71                2048  [0.8433496801948395, 0.8693166769047481, 0.890...   \n",
      "263               2048  [0.8904794377226107, 0.8980509131472884, 0.905...   \n",
      "455               2048  [0.5832819967581722, 0.6233610006662065, 0.668...   \n",
      "455               2048  [0.9235000000277982, 0.9234999999986135, 0.923...   \n",
      "647               2048  [0.9235000000000003, 0.9235000000000003, 0.923...   \n",
      "...                ...                                                ...   \n",
      "55623             1024  [0.44584552928013055, 0.4573933374907526, 0.46...   \n",
      "55815             2048  [0.53822470687768, 0.5676194133124589, 0.58390...   \n",
      "56391               64  [0.8657034537990438, 0.8703140586780724, 0.873...   \n",
      "56391             2048  [0.5426426648595437, 0.5509133936043613, 0.560...   \n",
      "56583             2048  [0.5716896183681022, 0.5739713126016285, 0.576...   \n",
      "\n",
      "                                                    beta  fails_init  \\\n",
      "71     [-0.19730679558849995, 0.059095845730495956, 0...           0   \n",
      "263    [-0.05865619308689036, 0.040433294301970436, 0...           0   \n",
      "455    [-0.47234725321255344, 0.016815680968895092, 0...           0   \n",
      "455    [1.90656201443135e-07, 0.5476696075426124, 0.9...           0   \n",
      "647    [126.57676969956037, 36.94760908924154, 0.9235...           0   \n",
      "...                                                  ...         ...   \n",
      "55623  [-0.09129767218743079, 0.06985023676319342, 0....           0   \n",
      "55815  [-0.3092072268035676, 0.107097427029717, 0.593...           0   \n",
      "56391  [-0.03772775806683164, 0.07611422397552484, 0....           0   \n",
      "56391  [-0.09856982586755075, 0.016539814656399806, 0...           0   \n",
      "56583  [-0.05784670621943182, 0.006380915565407469, 0...           0   \n",
      "\n",
      "       fails_fit       MSE_trn       MSE_tst  MSE_tst_last        L1_trn  \\\n",
      "71             0  1.202539e-05  1.226473e-05  1.226473e-05  3.086394e-03   \n",
      "263            0  6.548127e-06  4.281903e-06  4.281903e-06  2.366793e-03   \n",
      "455            0  1.204167e-04  4.199305e-04  4.199305e-04  9.530192e-03   \n",
      "455            0  5.522037e-23  4.129191e-24  4.129191e-24  3.706435e-12   \n",
      "647            0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "...          ...           ...           ...           ...           ...   \n",
      "55623          0  4.134403e-05  1.619747e-04  4.232258e-05  4.898428e-03   \n",
      "55815          0  2.907140e-06  1.560590e-07  1.560590e-07  1.223116e-03   \n",
      "56391          0  5.432286e-06  1.431290e-05  1.666232e-05  1.871892e-03   \n",
      "56391          0  4.328856e-05  3.377702e-04  3.377702e-04  5.386911e-03   \n",
      "56583          0  5.758928e-05  1.948375e-05  1.948375e-05  5.791099e-03   \n",
      "\n",
      "             L1_tst   L1_tst_last   n curve_model  \\\n",
      "71     3.502104e-03  3.502104e-03  15        exp3   \n",
      "263    2.069276e-03  2.069276e-03  15        exp3   \n",
      "455    2.049221e-02  2.049221e-02  15        exp3   \n",
      "455    2.032041e-12  2.032041e-12  15        exp3   \n",
      "647    0.000000e+00  0.000000e+00  15        exp3   \n",
      "...             ...           ...  ..         ...   \n",
      "55623  1.087594e-02  6.505580e-03  13        exp3   \n",
      "55815  3.950430e-04  3.950430e-04  15        exp3   \n",
      "56391  3.301878e-03  4.081950e-03   5        exp3   \n",
      "56391  1.837852e-02  1.837852e-02  15        exp3   \n",
      "56583  4.414040e-03  4.414040e-03  15        exp3   \n",
      "\n",
      "                                       anchor_prediction  \\\n",
      "71     [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
      "263    [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
      "455    [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
      "455    [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
      "647    [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
      "...                                                  ...   \n",
      "55623  [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
      "55815  [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
      "56391  [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
      "56391  [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
      "56583  [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
      "\n",
      "                                                   score  percentage  \\\n",
      "71     [0.8418999999999999, 0.8723449999999999, 0.888...    0.670596   \n",
      "263    [0.887335, 0.9016150000000002, 0.9066880000000...    0.670596   \n",
      "455    [0.5620543999999996, 0.6286088, 0.6818024, 0.7...    0.791345   \n",
      "455    [0.9235000000000003, 0.9235000000000003, 0.923...    0.670596   \n",
      "647    [0.9235000000000003, 0.9235000000000003, 0.923...    0.670596   \n",
      "...                                                  ...         ...   \n",
      "55623  [0.4457999999999999, 0.45649600000000007, 0.46...    0.011159   \n",
      "55815  [0.5371159999999999, 0.5715519999999998, 0.580...    0.632099   \n",
      "56391  [0.8656960000000001, 0.8710999999999999, 0.870...    0.010558   \n",
      "56391  [0.538568, 0.553772, 0.557788, 0.57378, 0.5902...    0.632099   \n",
      "56583  [0.552324, 0.58366, 0.5775560000000001, 0.5879...    0.632099   \n",
      "\n",
      "       percentage_bucket  \n",
      "71                  0.80  \n",
      "263                 0.80  \n",
      "455                 0.80  \n",
      "455                 0.80  \n",
      "647                 0.80  \n",
      "...                  ...  \n",
      "55623               0.05  \n",
      "55815               0.80  \n",
      "56391               0.05  \n",
      "56391               0.80  \n",
      "56583               0.80  \n",
      "\n",
      "[3769 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('use_inf_as_na',True)\n",
    "df_total = pd.read_pickle('data/df_total.gz').dropna()\n",
    "data = df_total[(df_total['curve_model'] == 'exp3')]\n",
    "# data = data[data['max_anchor_seen'] == 2048]\n",
    "data = data.loc[data.groupby(['openmlid', 'learner'])['max_anchor_seen'].idxmax()]\n",
    "\n",
    "q25 = data['MSE_tst_last'].quantile(0.5)\n",
    "data = data[data['MSE_tst_last'] < q25]\n",
    "\n",
    "print(data)\n",
    "\n",
    "x = [x[0] for x in data['beta']]\n",
    "y = [x[1] for x in data['beta']]\n",
    "z = [x[2] for x in data['beta']]\n",
    "# dd = [x[3] for x in data['beta']]\n",
    "\n",
    "betas = pd.DataFrame(zip(x,y,z), columns=['a', 'b', 'c'])\n",
    "# betas = betas[(betas['b'] > 1) | (betas['b'] < -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb515c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93017d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_params(idx):\n",
    "    a = betas['a'].iloc[idx]\n",
    "    b = betas['b'].iloc[idx]\n",
    "    c = betas['c'].iloc[idx]\n",
    "#     d = betas['d'].iloc[idx]\n",
    "    return a,b,c\n",
    "\n",
    "\n",
    "def run_experiment(ablation=False):\n",
    "    n = int(len(betas)) # number of LCs considered\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    asc = 0\n",
    "    desc = 0\n",
    "    \n",
    "    for i in tqdm(range(0,n)):\n",
    "        is_asc = False\n",
    "        flag = False\n",
    "        final_slopes = []\n",
    "        \n",
    "        lern = data['learner'].iloc[i]\n",
    "        dataset = data['openmlid'].iloc[i]\n",
    "        \n",
    "        a,b,c = gen_params(i)\n",
    "#         a,b,c,d = gen_params(i)\n",
    "        exp3 = lambda x: a * np.exp((-b) * x) + c # exp3 from LCDB\n",
    "#         mmf4 = lambda x: (a*b + c * (x ** d)) / (b + (x ** d))\n",
    "        anch = data['anchor_prediction'].iloc[i] # array of anchors\n",
    "        \n",
    "        if (a < 0 and b > 0) or (a > 0 and b < 0):\n",
    "            is_asc = True\n",
    "            asc+=1\n",
    "        else:\n",
    "            is_asc = False\n",
    "            desc+=1\n",
    "        \n",
    "        for j in range(0, len(anch)):\n",
    "            points = range(anch[j] - 10, anch[j] + 11)\n",
    "            errors_iterations = []\n",
    "            pp = []\n",
    "            slopes = []\n",
    "            for it in range(0, 25):\n",
    "#                 linreg_errs = []\n",
    "#                 for p in points:\n",
    "                noise = np.random.normal(0,0.002)\n",
    "                linreg_errs = [exp3(p)+noise for p in points]\n",
    "#                 for it in range(0,125):\n",
    "#                     pp.append(p)\n",
    "#                     noise = np.random.normal(0, 0.000001)\n",
    "#                     err = exp3(p) + noise\n",
    "#                     err_p.append(err)\n",
    "#                 errors_iterations.append(exp3(p)+np.random.normal(0,0.000001))\n",
    "                model = LinearRegression()\n",
    "                model.fit(np.array(points).reshape(-1,1), np.array(linreg_errs).reshape(-1,1))\n",
    "                if(model.coef_[0] > 0):\n",
    "                    slopes.append(1)\n",
    "                else:\n",
    "                    slopes.append(-1)\n",
    "            final_slopes.append(np.mean(slopes))\n",
    "        \n",
    "            \n",
    "            \n",
    "        for j in range(0, len(anch) - 1):\n",
    "            if ablation == True:\n",
    "                if final_slopes[j] > 0:\n",
    "                    if is_asc:\n",
    "                        true_pos+=1\n",
    "                    else:\n",
    "                        false_pos+=1\n",
    "                    flag = True\n",
    "                    break\n",
    "            else:\n",
    "                if final_slopes[j] > 0 and final_slopes[j+1] > 0:\n",
    "                    if is_asc:\n",
    "                        true_pos+=1\n",
    "                    else:\n",
    "                        false_pos+=1\n",
    "                        \n",
    "                    flag = True\n",
    "                    break\n",
    "                \n",
    "        if flag == False:\n",
    "            if is_asc:\n",
    "                false_neg+=1\n",
    "            else:\n",
    "                true_neg+=1\n",
    "\n",
    "\n",
    "    print(f\"Out of {n} Learning curves:\")\n",
    "    print(f\"-----------{asc} Non-monotonic LCs\")\n",
    "    print(f\"-----------{desc} Monotonic LCs\\n\")\n",
    "    print(f\" - {true_pos} Have been classified correctly as non-monotonic ({round((true_pos/asc)*100,2)}%)\")\n",
    "    print(f\" - {true_neg} Have been classified correctly as monotonic ({round((true_neg/desc)*100,2)}%)\")\n",
    "    print(f\" - {false_pos} Have been classified incorrectly as non-monotonic (Type I Error)\")\n",
    "    print(f\" - {false_neg} Have been classified incorrectly as monotonic (Type II Error)\")\n",
    "    return final_slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5236d3",
   "metadata": {},
   "source": [
    "# Experiment 2 - Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b1012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3769/3769 [26:01<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 3769 Learning curves:\n",
      "-----------3179 Non-monotonic LCs\n",
      "-----------590 Monotonic LCs\n",
      "\n",
      " - 3140 Have been classified correctly as non-monotonic (98.77%)\n",
      " - 554 Have been classified correctly as monotonic (93.9%)\n",
      " - 36 Have been classified incorrectly as non-monotonic (Type I Error)\n",
      " - 39 Have been classified incorrectly as monotonic (Type II Error)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 3746/3769 [26:08<00:07,  3.01it/s]"
     ]
    }
   ],
   "source": [
    "slopes_accuracy = run_experiment(ablation=False) # Run accuracy experiment\n",
    "slopes_ablation = run_experiment(ablation=True) # Run ablation study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed525299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1.885000e+03\n",
       "mean     3.020320e+217\n",
       "std                NaN\n",
       "min       0.000000e+00\n",
       "25%       1.330105e-06\n",
       "50%       2.156719e-05\n",
       "75%       3.057070e-04\n",
       "max      5.693304e+220\n",
       "Name: MSE_tst_last, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['MSE_tst_last'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b6151b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>openmlid</th>\n",
       "      <th>learner</th>\n",
       "      <th>max_anchor_seen</th>\n",
       "      <th>prediction</th>\n",
       "      <th>beta</th>\n",
       "      <th>fails_init</th>\n",
       "      <th>fails_fit</th>\n",
       "      <th>MSE_trn</th>\n",
       "      <th>MSE_tst</th>\n",
       "      <th>MSE_tst_last</th>\n",
       "      <th>L1_trn</th>\n",
       "      <th>L1_tst</th>\n",
       "      <th>L1_tst_last</th>\n",
       "      <th>n</th>\n",
       "      <th>curve_model</th>\n",
       "      <th>anchor_prediction</th>\n",
       "      <th>score</th>\n",
       "      <th>percentage</th>\n",
       "      <th>percentage_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.8881939184541461, 0.9127380493945678, 0.933...</td>\n",
       "      <td>[-0.18498168635445061, 0.053821398717900655, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.899628e-07</td>\n",
       "      <td>7.844349e-04</td>\n",
       "      <td>1.130185e-03</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.026241</td>\n",
       "      <td>0.033618</td>\n",
       "      <td>5</td>\n",
       "      <td>exp3</td>\n",
       "      <td>[16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...</td>\n",
       "      <td>[0.888184, 0.913108, 0.9322480000000002, 0.951...</td>\n",
       "      <td>0.009728</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>28</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.6109346065796966, 0.6786447625631157, 0.740...</td>\n",
       "      <td>[-0.5182087539484821, 0.04305895831083495, 0.8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.208965e-06</td>\n",
       "      <td>2.858538e-03</td>\n",
       "      <td>6.403439e-03</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.045723</td>\n",
       "      <td>0.080021</td>\n",
       "      <td>5</td>\n",
       "      <td>exp3</td>\n",
       "      <td>[16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...</td>\n",
       "      <td>[0.6104360000000001, 0.6787279999999999, 0.743...</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>57</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>2048</td>\n",
       "      <td>[0.8433496801948395, 0.8693166769047481, 0.890...</td>\n",
       "      <td>[-0.19730679558849995, 0.059095845730495956, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.202539e-05</td>\n",
       "      <td>1.226473e-05</td>\n",
       "      <td>1.226473e-05</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>15</td>\n",
       "      <td>exp3</td>\n",
       "      <td>[16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...</td>\n",
       "      <td>[0.8418999999999999, 0.8723449999999999, 0.888...</td>\n",
       "      <td>0.670596</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>390</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.1810382484579428, 0.23095369743606212, 0.28...</td>\n",
       "      <td>[-0.44146672878355747, 0.027653688710505483, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.516984e-06</td>\n",
       "      <td>8.066324e-02</td>\n",
       "      <td>1.689797e-01</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.253921</td>\n",
       "      <td>0.411071</td>\n",
       "      <td>5</td>\n",
       "      <td>exp3</td>\n",
       "      <td>[16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...</td>\n",
       "      <td>[0.18043599999999999, 0.23122399999999999, 0.2...</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>57</td>\n",
       "      <td>SVC_poly</td>\n",
       "      <td>2048</td>\n",
       "      <td>[0.8904794377226107, 0.8980509131472884, 0.905...</td>\n",
       "      <td>[-0.05865619308689036, 0.040433294301970436, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.548127e-06</td>\n",
       "      <td>4.281903e-06</td>\n",
       "      <td>4.281903e-06</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>15</td>\n",
       "      <td>exp3</td>\n",
       "      <td>[16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...</td>\n",
       "      <td>[0.887335, 0.9016150000000002, 0.9066880000000...</td>\n",
       "      <td>0.670596</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53719</th>\n",
       "      <td>41142</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.5338500247518796, 0.5458706737868025, 0.545...</td>\n",
       "      <td>[-196707.78847672566, 1.0381190869250136, 0.54...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.421882e-06</td>\n",
       "      <td>1.606092e-03</td>\n",
       "      <td>3.712334e-03</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.037224</td>\n",
       "      <td>0.060929</td>\n",
       "      <td>5</td>\n",
       "      <td>exp3</td>\n",
       "      <td>[16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...</td>\n",
       "      <td>[0.5338479999999999, 0.545976, 0.54344, 0.5508...</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54855</th>\n",
       "      <td>1499</td>\n",
       "      <td>sklearn.ensemble.RandomForestClassifier</td>\n",
       "      <td>128</td>\n",
       "      <td>[0.8667875950147348, 0.8685284592536817, 0.870...</td>\n",
       "      <td>[42.73813774966857, -5.818378839915116e-06, -4...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.469074e-06</td>\n",
       "      <td>2.218017e-04</td>\n",
       "      <td>2.218017e-04</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.014893</td>\n",
       "      <td>0.014893</td>\n",
       "      <td>7</td>\n",
       "      <td>exp3</td>\n",
       "      <td>[16, 23, 32, 45, 64, 91, 128, 170]</td>\n",
       "      <td>[0.8631440000000002, 0.8673519999999999, 0.875...</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55239</th>\n",
       "      <td>1499</td>\n",
       "      <td>sklearn.naive_bayes.BernoulliNB</td>\n",
       "      <td>128</td>\n",
       "      <td>[0.32236361797457075, 0.32320234751474086, 0.3...</td>\n",
       "      <td>[-0.00733077103272093, 0.028378669457045532, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.112467e-05</td>\n",
       "      <td>1.245481e-04</td>\n",
       "      <td>1.245481e-04</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>7</td>\n",
       "      <td>exp3</td>\n",
       "      <td>[16, 23, 32, 45, 64, 91, 128, 170]</td>\n",
       "      <td>[0.3263200000000001, 0.31580000000000014, 0.32...</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55815</th>\n",
       "      <td>42810</td>\n",
       "      <td>sklearn.naive_bayes.MultinomialNB</td>\n",
       "      <td>2048</td>\n",
       "      <td>[0.53822470687768, 0.5676194133124589, 0.58390...</td>\n",
       "      <td>[-0.3092072268035676, 0.107097427029717, 0.593...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.907140e-06</td>\n",
       "      <td>1.560590e-07</td>\n",
       "      <td>1.560590e-07</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>15</td>\n",
       "      <td>exp3</td>\n",
       "      <td>[16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...</td>\n",
       "      <td>[0.5371159999999999, 0.5715519999999998, 0.580...</td>\n",
       "      <td>0.632099</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56391</th>\n",
       "      <td>1002</td>\n",
       "      <td>sklearn.ensemble.ExtraTreesClassifier</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.8657034537990438, 0.8703140586780724, 0.873...</td>\n",
       "      <td>[-0.03772775806683164, 0.07611422397552484, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.432286e-06</td>\n",
       "      <td>1.431290e-05</td>\n",
       "      <td>1.666232e-05</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>5</td>\n",
       "      <td>exp3</td>\n",
       "      <td>[16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...</td>\n",
       "      <td>[0.8656960000000001, 0.8710999999999999, 0.870...</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       openmlid                                  learner  max_anchor_seen  \\\n",
       "71           24                               SVC_linear               64   \n",
       "71           28                               SVC_linear               64   \n",
       "71           57                               SVC_linear             2048   \n",
       "71          390                               SVC_linear               64   \n",
       "263          57                                 SVC_poly             2048   \n",
       "...         ...                                      ...              ...   \n",
       "53719     41142         sklearn.tree.ExtraTreeClassifier               64   \n",
       "54855      1499  sklearn.ensemble.RandomForestClassifier              128   \n",
       "55239      1499          sklearn.naive_bayes.BernoulliNB              128   \n",
       "55815     42810        sklearn.naive_bayes.MultinomialNB             2048   \n",
       "56391      1002    sklearn.ensemble.ExtraTreesClassifier               64   \n",
       "\n",
       "                                              prediction  \\\n",
       "71     [0.8881939184541461, 0.9127380493945678, 0.933...   \n",
       "71     [0.6109346065796966, 0.6786447625631157, 0.740...   \n",
       "71     [0.8433496801948395, 0.8693166769047481, 0.890...   \n",
       "71     [0.1810382484579428, 0.23095369743606212, 0.28...   \n",
       "263    [0.8904794377226107, 0.8980509131472884, 0.905...   \n",
       "...                                                  ...   \n",
       "53719  [0.5338500247518796, 0.5458706737868025, 0.545...   \n",
       "54855  [0.8667875950147348, 0.8685284592536817, 0.870...   \n",
       "55239  [0.32236361797457075, 0.32320234751474086, 0.3...   \n",
       "55815  [0.53822470687768, 0.5676194133124589, 0.58390...   \n",
       "56391  [0.8657034537990438, 0.8703140586780724, 0.873...   \n",
       "\n",
       "                                                    beta  fails_init  \\\n",
       "71     [-0.18498168635445061, 0.053821398717900655, 0...           0   \n",
       "71     [-0.5182087539484821, 0.04305895831083495, 0.8...           0   \n",
       "71     [-0.19730679558849995, 0.059095845730495956, 0...           0   \n",
       "71     [-0.44146672878355747, 0.027653688710505483, 0...           0   \n",
       "263    [-0.05865619308689036, 0.040433294301970436, 0...           0   \n",
       "...                                                  ...         ...   \n",
       "53719  [-196707.78847672566, 1.0381190869250136, 0.54...           0   \n",
       "54855  [42.73813774966857, -5.818378839915116e-06, -4...           0   \n",
       "55239  [-0.00733077103272093, 0.028378669457045532, 0...           0   \n",
       "55815  [-0.3092072268035676, 0.107097427029717, 0.593...           0   \n",
       "56391  [-0.03772775806683164, 0.07611422397552484, 0....           0   \n",
       "\n",
       "       fails_fit       MSE_trn       MSE_tst  MSE_tst_last    L1_trn  \\\n",
       "71             0  5.899628e-07  7.844349e-04  1.130185e-03  0.000624   \n",
       "71             0  4.208965e-06  2.858538e-03  6.403439e-03  0.001609   \n",
       "71             0  1.202539e-05  1.226473e-05  1.226473e-05  0.003086   \n",
       "71             0  2.516984e-06  8.066324e-02  1.689797e-01  0.001303   \n",
       "263            0  6.548127e-06  4.281903e-06  4.281903e-06  0.002367   \n",
       "...          ...           ...           ...           ...       ...   \n",
       "53719          0  7.421882e-06  1.606092e-03  3.712334e-03  0.002017   \n",
       "54855          0  6.469074e-06  2.218017e-04  2.218017e-04  0.001967   \n",
       "55239          0  1.112467e-05  1.245481e-04  1.245481e-04  0.002301   \n",
       "55815          0  2.907140e-06  1.560590e-07  1.560590e-07  0.001223   \n",
       "56391          0  5.432286e-06  1.431290e-05  1.666232e-05  0.001872   \n",
       "\n",
       "         L1_tst  L1_tst_last   n curve_model  \\\n",
       "71     0.026241     0.033618   5        exp3   \n",
       "71     0.045723     0.080021   5        exp3   \n",
       "71     0.003502     0.003502  15        exp3   \n",
       "71     0.253921     0.411071   5        exp3   \n",
       "263    0.002069     0.002069  15        exp3   \n",
       "...         ...          ...  ..         ...   \n",
       "53719  0.037224     0.060929   5        exp3   \n",
       "54855  0.014893     0.014893   7        exp3   \n",
       "55239  0.011160     0.011160   7        exp3   \n",
       "55815  0.000395     0.000395  15        exp3   \n",
       "56391  0.003302     0.004082   5        exp3   \n",
       "\n",
       "                                       anchor_prediction  \\\n",
       "71     [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
       "71     [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
       "71     [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
       "71     [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
       "263    [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
       "...                                                  ...   \n",
       "53719  [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
       "54855                 [16, 23, 32, 45, 64, 91, 128, 170]   \n",
       "55239                 [16, 23, 32, 45, 64, 91, 128, 170]   \n",
       "55815  [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
       "56391  [16, 23, 32, 45, 64, 91, 128, 181, 256, 362, 5...   \n",
       "\n",
       "                                                   score  percentage  \\\n",
       "71     [0.888184, 0.913108, 0.9322480000000002, 0.951...    0.009728   \n",
       "71     [0.6104360000000001, 0.6787279999999999, 0.743...    0.014060   \n",
       "71     [0.8418999999999999, 0.8723449999999999, 0.888...    0.670596   \n",
       "71     [0.18043599999999999, 0.23122399999999999, 0.2...    0.008268   \n",
       "263    [0.887335, 0.9016150000000002, 0.9066880000000...    0.670596   \n",
       "...                                                  ...         ...   \n",
       "53719  [0.5338479999999999, 0.545976, 0.54344, 0.5508...    0.014585   \n",
       "54855  [0.8631440000000002, 0.8673519999999999, 0.875...    0.752941   \n",
       "55239  [0.3263200000000001, 0.31580000000000014, 0.32...    0.752941   \n",
       "55815  [0.5371159999999999, 0.5715519999999998, 0.580...    0.632099   \n",
       "56391  [0.8656960000000001, 0.8710999999999999, 0.870...    0.010558   \n",
       "\n",
       "       percentage_bucket  \n",
       "71                  0.05  \n",
       "71                  0.05  \n",
       "71                  0.80  \n",
       "71                  0.05  \n",
       "263                 0.80  \n",
       "...                  ...  \n",
       "53719               0.05  \n",
       "54855               0.80  \n",
       "55239               0.80  \n",
       "55815               0.80  \n",
       "56391               0.05  \n",
       "\n",
       "[1885 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q25 = data['MSE_trn'].quantile(0.25)\n",
    "data[data['MSE_trn'] < q25]\n",
    "\n",
    "for idx in len(data):\n",
    "    row = data.iloc[idx]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
